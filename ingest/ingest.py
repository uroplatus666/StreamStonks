import os
import logging
import time
import schedule
from datetime import datetime, timedelta, timezone
import pandas as pd
import ta
import psycopg2
from psycopg2.extras import execute_values
from dotenv import load_dotenv
import keyring
from keyrings.alt import file
from TinvestPy import TinvestPy
from TinvestPy.grpc.marketdata_pb2 import GetCandlesRequest, CandleInterval

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞
keyring.set_keyring(file.PlaintextKeyring())
load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("IngestWorker")

TOKEN = os.environ.get("TINKOFF_TOKEN")
PG_HOST = os.getenv("POSTGRES_HOST", "localhost")
PG_USER = os.getenv("POSTGRES_USER", "mluser")
PG_PASS = os.getenv("POSTGRES_PASSWORD", "mlpass")
PG_DB = os.getenv("POSTGRES_DB", "marketdb")

# --- –°–ü–ò–°–û–ö –¢–ò–ö–ï–†–û–í ---
TICKERS_META = {
    # –ù–µ—Ñ—Ç–µ–≥–∞–∑
    "GAZP": ("–ì–∞–∑–ø—Ä–æ–º", "Energy"),
    "LKOH": ("–õ—É–∫–æ–π–ª", "Energy"),
    "ROSN": ("–†–æ—Å–Ω–µ—Ñ—Ç—å", "Energy"),
    "NVTK": ("–ù–æ–≤–∞—Ç—ç–∫", "Energy"),
    "TATN": ("–¢–∞—Ç–Ω–µ—Ñ—Ç—å", "Energy"),
    "SNGS": ("–°—É—Ä–≥—É—Ç–Ω–µ—Ñ—Ç–µ–≥–∞–∑", "Energy"),
    "SNGSP": ("–°—É—Ä–≥—É—Ç–Ω–µ—Ñ—Ç–µ–≥–∞–∑ (–ø—Ä–µ—Ñ)", "Energy"),
    "SIBN": ("–ì–∞–∑–ø—Ä–æ–º –Ω–µ—Ñ—Ç—å", "Energy"),
    "TRNFP": ("–¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å", "Energy"),
    "BANE": ("–ë–∞—à–Ω–µ—Ñ—Ç—å", "Energy"),

    # –§–∏–Ω–∞–Ω—Å—ã
    "SBER": ("–°–±–µ—Ä–±–∞–Ω–∫", "Financial"),
    "SBERP": ("–°–±–µ—Ä–±–∞–Ω–∫ (–ø—Ä–µ—Ñ)", "Financial"),
    "VTBR": ("–í–¢–ë", "Financial"),
    # "TCSG": ("–¢–ö–° –•–æ–ª–¥–∏–Ω–≥", "Financial"),
    "MOEX": ("–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –ë–∏—Ä–∂–∞", "Financial"),
    "CBOM": ("–ú–ö–ë", "Financial"),
    "BSPB": ("–ë–∞–Ω–∫ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "Financial"),

    # –ú–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è –∏ –¥–æ–±—ã—á–∞
    "GMKN": ("–ù–æ—Ä–Ω–∏–∫–µ–ª—å", "Materials"),
    "PLZL": ("–ü–æ–ª—é—Å", "Materials"),
    "ALRS": ("–ê–ª—Ä–æ—Å–∞", "Materials"),
    "RUAL": ("–†—É—Å–∞–ª", "Materials"),
    "CHMF": ("–°–µ–≤–µ—Ä—Å—Ç–∞–ª—å", "Materials"),
    "NLMK": ("–ù–õ–ú–ö", "Materials"),
    "MAGN": ("–ú–ú–ö", "Materials"),
    "PHOR": ("–§–æ—Å–ê–≥—Ä–æ", "Materials"),
    "SELG": ("–°–µ–ª–∏–≥–¥–∞—Ä", "Materials"),

    # IT –∏ –¢–µ–ª–µ–∫–æ–º
    "YDEX": ("–Ø–Ω–¥–µ–∫—Å –ú–ö–ü–ê–û", "Technology"),
    "MTSS": ("–ú–¢–°", "Telecom"),
    "RTKM": ("–†–æ—Å—Ç–µ–ª–µ–∫–æ–º", "Telecom"),
    "VKCO": ("VK", "Technology"),
    "POSI": ("Positive Technologies", "Technology"),
    "OZON": ("Ozon", "Consumer Cyclical"),
    "ASTR": ("–ê—Å—Ç—Ä–∞", "Technology"),

    # –ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π —Å–µ–∫—Ç–æ—Ä
    "MGNT": ("–ú–∞–≥–Ω–∏—Ç", "Consumer Defensive"),
    "FIVE": ("X5 Group", "Consumer Defensive"),
    "BELU": ("Novabev (–ë–µ–ª—É–≥–∞)", "Consumer Defensive"),
    "AQUA": ("–ò–Ω–∞—Ä–∫—Ç–∏–∫–∞", "Consumer Defensive"),

    # –ú–µ–¥–∏—Ü–∏–Ω–∞ (Healthcare)
    "MDMG": ("–ú–∞—Ç—å –∏ –¥–∏—Ç—è", "Healthcare"),
    "ABIO": ("–ê—Ä—Ç–≥–µ–Ω –±–∏–æ—Ç–µ—Ö", "Healthcare"),
    "GEMC": ("–ï–≤—Ä–æ–ú–µ–¥–¶–µ–Ω—Ç—Ä", "Healthcare"),

    # –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å
    "PIKK": ("–ü–ò–ö", "Real Estate"),
    "SMLT": ("–°–∞–º–æ–ª–µ—Ç", "Real Estate"),
    "LSRG": ("–õ–°–†", "Real Estate"),

    # –≠–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞
    "IRAO": ("–ò–Ω—Ç–µ—Ä –†–ê–û", "Utilities"),
    "HYDR": ("–†—É—Å–ì–∏–¥—Ä–æ", "Utilities"),
    "FEES": ("–§–°–ö - –†–æ—Å—Å–µ—Ç–∏", "Utilities"),
    "MSNG": ("–ú–æ—Å—ç–Ω–µ—Ä–≥–æ", "Utilities"),

    # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç
    "AFLT": ("–ê—ç—Ä–æ—Ñ–ª–æ—Ç", "Industrials"),
    "FLOT": ("–°–æ–≤–∫–æ–º—Ñ–ª–æ—Ç", "Industrials")
}



def get_db_connection():
    return psycopg2.connect(host=PG_HOST, dbname=PG_DB, user=PG_USER, password=PG_PASS)


def init_tickers_metadata():
    """–ó–∞–ø–æ–ª–Ω—è–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Ç–∏–∫–µ—Ä–æ–≤"""
    conn = get_db_connection()
    cur = conn.cursor()
    query = """
        INSERT INTO tickers (symbol, company_name, sector) VALUES %s
        ON CONFLICT (symbol) DO UPDATE SET company_name = EXCLUDED.company_name;
    """
    data = [(t, m[0], m[1]) for t, m in TICKERS_META.items()]
    execute_values(cur, query, data)
    conn.commit()
    conn.close()


def get_latest_timestamp(ticker):
    """–£–∑–Ω–∞–µ–º, –∫–æ–≥–¥–∞ –±—ã–ª–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–ø–∏—Å—å –≤ –ë–î –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–∫–µ—Ä–∞"""
    conn = get_db_connection()
    cur = conn.cursor()
    cur.execute("SELECT MAX(ts) FROM market_candles WHERE ticker = %s", (ticker,))
    res = cur.fetchone()
    conn.close()
    if res and res[0]:
        return res[0]
    return None


def get_figi_by_ticker(provider, ticker):
    try:
        return provider.get_symbol_info('TQBR', ticker).figi
    except:
        return None


def download_candles_chunked(provider, figi, start, end):
    """–ö–∞—á–∞–µ—Ç —Å–≤–µ—á–∏ —á–∞–Ω–∫–∞–º–∏ –ø–æ 7 –¥–Ω–µ–π, —á—Ç–æ–±—ã API –Ω–µ —Ä—É–≥–∞–ª—Å—è"""
    interval = CandleInterval.CANDLE_INTERVAL_HOUR
    all_candles = []

    current_start = start
    # API –¢–∏–Ω—å–∫–æ—Ñ—Ñ –ª—É—á—à–µ –ø–µ—Ä–µ–≤–∞—Ä–∏–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –ø–æ –Ω–µ–¥–µ–ª—è–º
    chunk_size = timedelta(days=7)

    while current_start < end:
        current_end = min(current_start + chunk_size, end)

        req = GetCandlesRequest(instrument_id=figi, interval=interval)
        getattr(req, 'from').seconds = int(current_start.timestamp())
        getattr(req, 'to').seconds = int(current_end.timestamp())

        try:
            resp = provider.call_function(provider.stub_marketdata.GetCandles, req)
            if resp.candles:
                for c in resp.candles:
                    ts = datetime.fromtimestamp(c.time.seconds, timezone.utc)
                    all_candles.append({
                        "ts": ts, "open": provider.quotation_to_float(c.open),
                        "high": provider.quotation_to_float(c.high), "low": provider.quotation_to_float(c.low),
                        "close": provider.quotation_to_float(c.close), "volume": c.volume
                    })
        except Exception as e:
            logger.warning(f"Chunk failed {current_start}: {e}")
            time.sleep(1)  # –ü–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            
        time.sleep(0.2)
        current_start = current_end

    return pd.DataFrame(all_candles)


def process_data(df):
    if df.empty: return df
    df = df.sort_values('ts').drop_duplicates(subset=['ts']).reset_index(drop=True)

    # Technical Analysis
    df['rsi'] = ta.momentum.rsi(df['close'], window=14)
    df['macd'] = ta.trend.macd_diff(df['close'])

    df = df.dropna()
    return df


def save_to_db(ticker, df):
    if df.empty: return
    conn = get_db_connection()
    cur = conn.cursor()
    records = []
    for row in df.itertuples():
        records.append(
            (ticker, row.ts, row.open, row.high, row.low, row.close, row.volume, row.macd, row.rsi, row.ts.weekday(),
             row.ts.hour))

    query = """
        INSERT INTO market_candles (ticker, ts, open, high, low, close, volume, macd, rsi, day_of_week, time_of_day)
        VALUES %s ON CONFLICT (ticker, ts) DO NOTHING
    """
    execute_values(cur, query, records)
    conn.commit()
    conn.close()


def sync_tickers(backfill_years=5):
    """–£–º–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: –∫–∞—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ò–õ–ò –¥–æ–∫–∞—á–∏–≤–∞–µ—Ç —Å–≤–µ–∂–µ–µ"""
    logger.info("üîÑ STARTING SYNC PROCESS...")

    if not TOKEN:
        logger.error("No Token!")
        return

    try:
        provider = TinvestPy(token=TOKEN)
        now_time = datetime.now(timezone.utc)

        for ticker in TICKERS_META.keys():
            figi = get_figi_by_ticker(provider, ticker)
            if not figi:
                logger.warning(f"Skipping {ticker}: FIGI not found")
                continue

            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –≤ –ë–î
            last_ts = get_latest_timestamp(ticker)

            if last_ts:
                # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å -> –∫–∞—á–∞–µ–º —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞ –¥–æ —Å–µ–π—á–∞—Å
                start_time = last_ts
                mode = "LIVE UPDATE"
            else:
                # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç -> –∫–∞—á–∞–µ–º 5 –ª–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ (Backfill)
                start_time = now_time - timedelta(days=365 * backfill_years)
                mode = "FULL BACKFILL (5 Years)"

            # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —Å–ª–∏—à–∫–æ–º —Å–≤–µ–∂–∏–µ, –Ω–µ –º—É—á–∞–µ–º API
            if (now_time - start_time).total_seconds() < 600:
                logger.info(f"‚è≠Ô∏è {ticker} is up to date.")
                continue

            logger.info(f"üì• {mode} for {ticker}: {start_time} -> {now_time}")

            df = download_candles_chunked(provider, figi, start_time, now_time)

            if not df.empty:
                df = process_data(df)
                save_to_db(ticker, df)
                logger.info(f"‚úÖ Saved {len(df)} rows for {ticker}")
            else:
                logger.info(f"‚ö†Ô∏è No new data for {ticker}")

            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ —É–±–∏—Ç—å API –ª–∏–º–∏—Ç–∞–º–∏
            time.sleep(0.5)

        provider.close_channel()
        logger.info("üèÅ SYNC COMPLETE")

    except Exception as e:
        logger.error(f"Sync failed: {e}")


# –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ (–≤—Å–µ–≥–¥–∞ —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞–∑–∞–¥ –Ω–∞ 3 –¥–Ω—è –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏)
def scheduled_job():
    # –í —Ä–µ–∂–∏–º–µ Live –Ω–∞–º –Ω–µ –Ω—É–∂–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ 5 –ª–µ—Ç –Ω–∞–∑–∞–¥ –∫–∞–∂–¥—ã–π —Ä–∞–∑.
    # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3-7 –¥–Ω–µ–π, —á—Ç–æ–±—ã –ø–µ—Ä–µ–∫—Ä—ã—Ç—å –≤—ã—Ö–æ–¥–Ω—ã–µ/–ø—Ä–∞–∑–¥–Ω–∏–∫–∏
    # –õ–æ–≥–∏–∫–∞ sync_tickers —Å–∞–º–∞ —Ä–∞–∑–±–µ—Ä–µ—Ç—Å—è —á–µ—Ä–µ–∑ get_latest_timestamp,
    # –Ω–æ —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∞—Ç—å –ª–∏—à–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ count(), –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –≤—ã–∑—ã–≤–∞—Ç—å sync_tickers
    sync_tickers(backfill_years=5)


if __name__ == "__main__":
    # 1. –ñ–î–ï–ú –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–Ø –ö –ë–î
    logger.info("‚è≥ Waiting for Database connection...")
    while True:
        try:
            init_tickers_metadata()
            logger.info("‚úÖ Database connection established.")
            break
        except Exception as e:
            logger.warning(f"Database not ready yet ({e}). Retrying in 5s...")
            time.sleep(5)

    # 2. –ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö
    logger.info("üöÄ Initializing Data Load...")
    sync_tickers(backfill_years=5)

    # 3. –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
    schedule.every(10).minutes.do(scheduled_job)

    logger.info("‚è∞ Scheduler started. Waiting for next window...")
    while True:
        schedule.run_pending()
        time.sleep(1)